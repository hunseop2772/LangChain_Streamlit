{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5630b0ca",
   "metadata": {
    "id": "5630b0ca"
   },
   "source": [
    "# **Retrieval Augmented Generation (RAG) 애플리케이션 구축: Part 1**\n",
    "\n",
    "### 자신만의 문서를 활용하여 응답을 생성하는 애플리케이션 구축\n",
    "\n",
    "- **Part 1**: RAG 개념을 소개하고, 최소한의 구현 방법을 설명합니다.  \n",
    "- **Part 2** 기존 구현을 확장하여 대화형 상호작용과 다단계 검색 프로세스를 처리할 수 있도록 개선합니다.\n",
    "---\n",
    "\n",
    "## 전형적인 **RAG 애플리케이션**\n",
    "\n",
    "두 가지 주요 구성 요소로 이루어져 있습니다:  \n",
    "\n",
    "1. **인덱싱(Indexing)**: 데이터 소스를 수집하고 인덱싱하는 파이프라인입니다. *일반적으로 오프라인에서 수행됩니다.*  \n",
    "2. **검색 및 생성(Retrieval and Generation)**: 실행 시간에 사용자 쿼리를 받아 인덱스에서 관련 데이터를 검색한 후, 모델에 전달하여 답변을 생성합니다.  \n",
    "\n",
    "---\n",
    "\n",
    "### **인덱싱 단계**  \n",
    "일반적인 데이터 인덱싱 과정은 다음과 같습니다:  \n",
    "\n",
    "1. **로드(Load)**  \n",
    "   - 먼저 데이터를 불러와야 합니다. 이는 문서 로더(Document Loaders)를 사용하여 수행됩니다.  \n",
    "\n",
    "2. **분할(Split)**  \n",
    "   - 텍스트 분할기(Text Splitters)를 사용해 큰 `문서(Document)`를 작은 청크(chunk)로 나눕니다.  \n",
    "   - 이렇게 하면 검색이 더 효율적이며, 모델의 제한된 컨텍스트 윈도우에 맞출 수 있습니다.  \n",
    "\n",
    "3. **저장(Store)**  \n",
    "   - 분할된 데이터를 저장하고 인덱싱할 장소가 필요합니다.  \n",
    "   - 일반적으로 벡터 스토어(VectorStore)와 임베딩 모델(Embeddings)을 사용합니다.  \n",
    "\n",
    "![index_diagram](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/rag_indexing.png?raw=1)\n",
    "\n",
    "---\n",
    "\n",
    "### **검색 및 생성 단계**  \n",
    "\n",
    "일반적인 검색 및 생성 과정은 다음과 같습니다:  \n",
    "\n",
    "4. **검색(Retrieve)**  \n",
    "   - 사용자 입력을 받아 검색기(Retriever)를 사용하여 저장된 데이터에서 관련 청크를 검색합니다.  \n",
    "\n",
    "5. **생성(Generate)**  \n",
    "   - 챗 모델(ChatModel) 또는 LLM이 검색된 데이터를 포함한 프롬프트를 사용해 답변을 생성합니다.  \n",
    "\n",
    "![retrieval_diagram](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/rag_retrieval_generation.png?raw=1)\n",
    "\n",
    "---\n",
    "\n",
    "인덱싱이 완료된 후에는 LangGraph를 오케스트레이션 프레임워크로 사용하여 **검색 및 생성 단계**를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f3a87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ab6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적 설정 활성화\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba74a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 사용할 언어 모델의 이름을 지정\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "# 사용할 임베딩 모델의 이름을 지정\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92cbc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InMemoryVectorStore - 메모리 내에서 벡터 데이터를 저장 및 빠른 검색\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466846eb-cf30-447e-85f1-03fc890d9fbf",
   "metadata": {
    "id": "MbLyI5UuawNz"
   },
   "source": [
    "LangSmith를 살펴보면 [LangSmith 추적](https://smith.langchain.com/o/351c6cd9-1396-5c74-9478-1ee6a22a6433/projects/p/acec9d4d-4978-4597-adff-789cd42e200f?timeModel=%7B%22duration%22%3A%227d%22%7D)에서 정확히 무슨 일이 일어나고 있는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2d316-922c-4318-b72d-486fd6813b94",
   "metadata": {
    "id": "93b2d316-922c-4318-b72d-486fd6813b94"
   },
   "source": [
    "이  노트북에서는 **웹사이트 콘텐츠에 대한 질문에 답변하는 애플리케이션**을 구축합니다.  \n",
    "약 **50줄의 코드**로 간단한 **인덱싱 파이프라인**과 **RAG 체인**을 만들 수 있습니다.   \n",
    "**텍스트를 로드, 분할, 인덱싱**한 후, **사용자 질문을 기반으로 관련 데이터를 검색**하고 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10644e09-b667-4a28-b066-5447339125a0",
   "metadata": {},
   "source": [
    "## **단계별 상세 설명**\n",
    "\n",
    "## **1. 인덱싱 (Indexing)**\n",
    "\n",
    "### **문서 불러오기 (Loading Documents)**\n",
    "\n",
    "우리가 콘텐츠를 불러올 웹사이트는 **[Harheem의 \"LLM Agents\" 블로그 게시물](https://harheem.github.io/llm/2024/02/28/llm-agents.html)** 이며, 이를 통해 해당 게시물의 내용에 대한 질문에 답할 수 있도록 할 것입니다.\n",
    "먼저 블로그 게시물의 내용을 불러와야 합니다. 이를 위해 **Document Loaders** 중 **[WebBaseLoader](https://python.langchain.com/docs/integrations/document_loaders/web_base/)** 를 사용합니다. 이 객체는 데이터 소스에서 정보를 불러와 **Document** 객체 목록으로 반환합니다.\n",
    "\n",
    "이 경우,\n",
    "\n",
    "* `WebBaseLoader`는 내부적으로 `urllib`을 사용해 **웹 URL에서 HTML을 로드**합니다.\n",
    "* 이후, `BeautifulSoup`을 사용해 **텍스트로 파싱**합니다.\n",
    "\n",
    "#### **HTML → 텍스트 변환 커스터마이징**\n",
    "\n",
    "* 우리는 `<h1>`, `<h2>`, `<h3>`, `<p>`, `<pre>`, `<li>` 등 주요 콘텐츠를 포함하는 태그만 추출하도록 설정합니다.\n",
    "* 또한 일부 웹사이트에서는 User-Agent를 설정하지 않으면 콘텐츠를 차단할 수 있으므로, `requests_kwargs`를 사용해 User-Agent를 지정해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06fc9cc-1bd5-42d0-a0a8-cd6d93b7410a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 9483\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 주요 콘텐츠 태그만 필터링 (제목, 본문, 코드 등)\n",
    "bs4_strainer = bs4.SoupStrainer(name=(\"h1\", \"h2\", \"h3\", \"p\", \"pre\", \"li\"))\n",
    "\n",
    "# WebBaseLoader 사용: requests_kwargs로 User-Agent 설정\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://harheem.github.io/llm/2024/02/28/llm-agents.html\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    "    requests_kwargs={\n",
    "        \"headers\": {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 결과 확인\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8643579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9483\n",
      "\n",
      "LLM Agents\n",
      "Prompt Engineering Guide 한글화 - LLM Agents\n",
      "LLM AgentsLLM 에이전트 프레임워크에이전트계획피드백이 없는 계획피드백이 있는 계획메모리도구LLM 에이전트 응용 사례주목할 만한 LLM 에이전트 사례LLM 에이전트 도구LLM 에이전트 평가도전과제참고 자료ResumeBlog\n",
      "LLM Agents\n",
      "Prompt Engineering Guide 한글화 - LLM Agents\n",
      "LLM AgentsPrompt Engineering Guide - LLM AgentsTranslate llm-agents.en.mdx to Korean in llm-agents.kr.mdx by harheem · Pull Request #406 · dair-ai/Prompt-Engineering-GuideLLM 기반 에이전트는 계획 및 메모리와 같은 핵심 모듈과 결합된 LLM을 통해 복잡한 작업을 수행할 수 있는 LLM 애플리케이션을 의미합니다. 여기서 LLM은 작업이\n"
     ]
    }
   ],
   "source": [
    "# 문서 길이\n",
    "print(len(docs[0].page_content))\n",
    "# 첫번째 500 자 출력\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f11795-e19f-4697-bc6e-6d477355a1cd",
   "metadata": {
    "id": "e6f11795-e19f-4697-bc6e-6d477355a1cd"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **문서 분할 (Splitting documents)**  \n",
    "\n",
    "불러온 문서는 **42,000자 이상**으로, 많은 언어 모델의 **컨텍스트 윈도우(context window)** 에 넣기에는 너무 길므로, 너무 긴 입력은 **정보를 효과적으로 찾아내기 어려울 수 있습니다.**  \n",
    "\n",
    "이 문제를 해결하기 위해, **`Document`를 작은 청크(chunk)로 분할**하여 **임베딩(embedding)** 및 **벡터 저장(vector storage)** 에 사용합니다.  \n",
    "이렇게 하면 블로그 게시물의 **가장 관련성 높은 부분만 검색**할 수 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "**RecursiveCharacterTextSplitter**는 문서를 **공통 구분자(예: 줄바꿈)** 를  사용해 재귀적으로 분할합니다.  일반적인 텍스트 사용 사례에 가장 적합한 텍스트 분할기입니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6606d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "블로그 글을 13개의 하위 문서로 분할했습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,            # 각 청크의 최대 문자 수 (1,000자)\n",
    "    chunk_overlap=200,          # 청크 간 겹치는 문자 수 (200자)\n",
    "    add_start_index=True,       # 원본 문서에서 각 청크의 시작 인덱스를 추적\n",
    ")\n",
    "\n",
    "# 불러온 문서를 설정한 기준에 따라 청크로 분할\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 분할된 청크(서브 문서)의 개수 출력\n",
    "print(f\"블로그 글을 {len(all_splits)}개의 하위 문서로 분할했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "024f0446-4d6b-488e-afd2-073a992f3e94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 1}, page_content='LLM Agents\\nPrompt Engineering Guide 한글화 - LLM Agents\\nLLM AgentsLLM 에이전트 프레임워크에이전트계획피드백이 없는 계획피드백이 있는 계획메모리도구LLM 에이전트 응용 사례주목할 만한 LLM 에이전트 사례LLM 에이전트 도구LLM 에이전트 평가도전과제참고 자료ResumeBlog\\nLLM Agents\\nPrompt Engineering Guide 한글화 - LLM Agents'),\n",
       " Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 236}, page_content='LLM AgentsPrompt Engineering Guide - LLM AgentsTranslate llm-agents.en.mdx to Korean in llm-agents.kr.mdx by harheem · Pull Request #406 · dair-ai/Prompt-Engineering-GuideLLM 기반 에이전트는 계획 및 메모리와 같은 핵심 모듈과 결합된 LLM을 통해 복잡한 작업을 수행할 수 있는 LLM 애플리케이션을 의미합니다. 여기서 LLM은 작업이나 사용자 요청을 완료하는 데 필요한 작업 흐름을 제어하는 주요 컨트롤러 또는 ‘두뇌’ 역할을 합니다. LLM 에이전트는 계획, 메모리, 도구와 같은 다양한 핵심 모듈이 필요할 수 있습니다.이 LLM 에이전트의 유용성을 더 잘 이해하기 위해, 다음과 같은 시스템을 구축하는 데 관심이 있다고 생각해 보겠습니다:2023년 미국의 평균 일일 칼로리 섭취량은 얼마인가요?위 질문은 이미 충분한 지식을 갖춘 LLM을 통해 바로 답할 수 있을 것입니다. 만약 LLM이 해당 질문에 대한 지식이 없다면, LLM은 건강 관련 정보나 보고서에 접근할 수 있는 간단한 RAG 시스템을 활용할 수 있습니다. 이제 보다 복잡한 질문을 시도해 보겠습니다:지난 10년 동안 미국 성인의 평균 일일 칼로리 섭취 추세는 어떻게 변했으며, 이것이 비만률에 어떤 영향을 미쳤나요? 또한, 이 기간 동안 비만률 추세의 그래픽 표현을 제공할 수 있나요?이 질문에 대답하기 위해서는 단순히 LLM만 사용하는 것으로는 충분하지 않습니다. LLM을 외부 지식 베이스와 결합한 RAG 시스템을 만드는 것도 이런 복잡한 질문에 대한 답변을 제공하기엔 부족할 수 있습니다. 이런 질문에 대응하기 위해서는 LLM이 필요한 도구를 활용하고, 목표로 하는 최종 응답을 위한 작업 흐름을 관리하며, 작업을 세분화하는 과정이 필요합니다. 한 가지 해결책으로는 LLM 에이전트를 구축하여 검색 API, 건강 관련 출판물, 칼로리 섭취 및 비만과 관련된 정보를 제공하는'),\n",
       " Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 1037}, page_content='것도 이런 복잡한 질문에 대한 답변을 제공하기엔 부족할 수 있습니다. 이런 질문에 대응하기 위해서는 LLM이 필요한 도구를 활용하고, 목표로 하는 최종 응답을 위한 작업 흐름을 관리하며, 작업을 세분화하는 과정이 필요합니다. 한 가지 해결책으로는 LLM 에이전트를 구축하여 검색 API, 건강 관련 출판물, 칼로리 섭취 및 비만과 관련된 정보를 제공하는 공공 및 사적 건강 데이터베이스에 접근할 수 있도록 하는 것입니다.LLM은 비만 추세를 분석하는 데 도움이 되는 차트를 생성하기 위해 데이터를 처리하는 코드 인터프리터 도구에 접근해야 할 것입니다. 이러한 도구는 LLM 에이전트가 고려할 수 있는 고급 기능 중 하나입니다. 또한, 작업 계획을 세우고 작업 흐름을 관리하며, 진행 상황을 추적하는 데 유용한 메모리 모듈에 대한 접근도 중요한 고려 사항 중 하나입니다.LLM 에이전트 프레임워크일반적으로 LLM 에이전트 프레임워크는 다음과 같은 핵심 구성 요소로 이루어질 수 있습니다:사용자 요청(User Request) - 사용자의 질문이나 요청에이전트(Agent)/두뇌(Brain) - 관리자의 역할을 하는 에이전트의 핵심계획(Planning) - 에이전트가 미래 행동을 계획하는 것을 도움메모리(Memory) - 에이전트의 과거 행동을 관리에이전트대규모 언어 모델(LLM)은 시스템의 핵심 두뇌로서, 에이전트 모듈이나 관리자의 역할을 수행합니다. 이 구성 요소는 에이전트의 작동 방식과 접근 가능한 도구(도구의 세부 정보 포함)에 대한 중요한 세부 정보를 담은 프롬프트 템플릿을 통해 활성화됩니다.필수는 아니지만, 에이전트는 특정 역할이나 특성을 가진 페르소나로 프로파일링될 수 있습니다. 이 프로파일링 정보는 주로 프롬프트에 기재되며, 역할 세부 정보, 성격, 사회적 배경, 인구 통계적 정보 등 구체적인 사항을 포함할 수 있습니다. Wang et al. 2023에 따르면, 에이전트 프로파일을 정의하는 방법으로는 수작업, LLM 생성, 데이터 기반 접근법이'),\n",
       " Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 1826}, page_content='아니지만, 에이전트는 특정 역할이나 특성을 가진 페르소나로 프로파일링될 수 있습니다. 이 프로파일링 정보는 주로 프롬프트에 기재되며, 역할 세부 정보, 성격, 사회적 배경, 인구 통계적 정보 등 구체적인 사항을 포함할 수 있습니다. Wang et al. 2023에 따르면, 에이전트 프로파일을 정의하는 방법으로는 수작업, LLM 생성, 데이터 기반 접근법이 있습니다.계획피드백이 없는 계획계획 모듈은 에이전트가 사용자의 요청에 답하기 위해 해결해야 할 단계나 하위 작업들을 세분화하는 데 도움을 줍니다. 이러한 단계는 에이전트가 문제를 더 효과적으로 추론하고 신뢰할 수 있는 해결책을 찾는 데 필요합니다. 계획 모듈은 LLM을 이용하여 사용자의 질문에 도움이 되는 하위 작업을 포함한 상세한 계획을 만듭니다. 작업 분해에 사용되는 인기 있는 기술로는 Chain of Thought와  Tree of Thoughts가 있으며, 이는 단일 경로 추론과 다중 경로 추론으로 구분될 수 있습니다.  아래는 Wang et al. 2023에서 다양한 전략을 비교한 그림입니다:피드백이 있는 계획위에서 언급한 계획 모듈들은 피드백이 없어 복잡한 작업에 대한 장기적인 계획을 세우는 데 어려움을 겪습니다. 이 문제를 해결하기 위해, 모델이 과거 행동과 관찰을 바탕으로 실행 계획을 반복적으로 평가하고 조정하는 메커니즘을 사용할 수 있습니다. 목표는 과거의 실수를 수정하고 개선하여 최종 결과의 질을 높이는 것입니다. 이는 특히 복잡한 실제 환경 및 작업에서 시행착오가 중요한 역할을 할 때 중요합니다. 이런 메커니즘을 위한 두 가지 인기 있는 방법에는 ReAct와 Reflexion이 있습니다.ReAct는 추론과 행동을 결합하여 LLM이 여러 단계(반복적으로 N회 실행)를 번갈아 가면서 복잡한 작업을 해결할 수 있도록 합니다. 이 단계들은 생각, 행동, 관찰로 구성됩니다. ReAct는 환경으로부터 관찰 형태의 피드백을 받습니다. 다른 유형의 피드백으로는 인간과 모델 피드백이 포함될 수 있습니다.'),\n",
       " Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 2626}, page_content='방법에는 ReAct와 Reflexion이 있습니다.ReAct는 추론과 행동을 결합하여 LLM이 여러 단계(반복적으로 N회 실행)를 번갈아 가면서 복잡한 작업을 해결할 수 있도록 합니다. 이 단계들은 생각, 행동, 관찰로 구성됩니다. ReAct는 환경으로부터 관찰 형태의 피드백을 받습니다. 다른 유형의 피드백으로는 인간과 모델 피드백이 포함될 수 있습니다. 아래 그림은 ReAct의 예시와 질문에 답하는 데 관련된 다양한 단계들을 보여줍니다:ReAct에 대해서 더 자세히 알고 싶다면 아래 문서를 참고하세요:https://www.promptingguide.ai/techniques/react메모리메모리 모듈은 에이전트와 사용자 간의 모든 상호작용, 환경에서의 과거 생각, 행동 및 관찰을 포함하는 에이전트의 내부 로그를 저장하는 데 도움을 줍니다. LLM 에이전트 관련 문헌에서 언급되는 주요 메모리 유형은 다음과 같습니다:단기 기억(Short-term memory) - 에이전트의 현재 상황에 대한 컨텍스트 정보를 포함합니다. 이는 대체로 컨텍스트 윈도우의 제한으로 인해 짧고 유한한 문맥 내 학습으로 구현됩니다.장기 기억(Long-term memory) - 에이전트의 과거 행동과 생각을 장기간 보존하고 회상해야 하는 내용을 포함합니다. 이는 에이전트가 필요에 따라 관련 정보를 빠르고 확장 가능한 검색을 통해 접근하는 외부 벡터 저장소를 사용하는 경우가 많습니다.하이브리드 메모리는 단기 기억과 장기 기억을 통합하여 에이전트의 장기적 추론 능력과 경험 축적 능력을 강화합니다.에이전트를 구축할 때 고려할 수 있는 다양한 메모리 형식도 있습니다. 여기에는 자연 언어, 임베딩, 데이터베이스, 구조화된 리스트 등이 포함되며, 이들은 자연 언어로 표현된 키와 임베딩 벡터로 표현된 값으로 구성된 키-값 구조를 활용하는 Minecraft의 Ghost (GITM)와 같이 결합될 수 있습니다.계획 및 메모리 모듈은 에이전트가 동적 환경에서 효과적으로 작동하고 과거 행동을 잘 회상하며 미래'),\n",
       " Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 3428}, page_content='형식도 있습니다. 여기에는 자연 언어, 임베딩, 데이터베이스, 구조화된 리스트 등이 포함되며, 이들은 자연 언어로 표현된 키와 임베딩 벡터로 표현된 값으로 구성된 키-값 구조를 활용하는 Minecraft의 Ghost (GITM)와 같이 결합될 수 있습니다.계획 및 메모리 모듈은 에이전트가 동적 환경에서 효과적으로 작동하고 과거 행동을 잘 회상하며 미래 행동을 계획할 수 있도록 합니다.도구도구는 LLM 에이전트가 외부 환경과 상호 작용하는 데 도움을 주는 도구나 도구 집합을 의미합니다. 여기에는 위키피디아 검색 API, 코드 인터프리터, 수학 엔진 등이 포함됩니다. 또한, 데이터베이스, 지식 베이스, 외부 모델도 도구에 포함될 수 있습니다. 에이전트가 외부 도구와 상호작용할 때는 사용자 요청을 충족시키고 부분 작업을 완료하기 위해 필요한 관찰이나 정보를 얻는 워크플로우를 통해 작업을 수행합니다. 예를 들어, 건강 관련 질문에서 코드 인터프리터는 사용자가 요청한 필요한 차트 정보를 생성하는 코드를 실행하는 도구가 됩니다.LLM은 다양한 방식으로 도구를 활용합니다:MRKL은 LLM과 전문가 모듈을 결합한 프레임워크로, 이는 LLM 또는 기호식(계산기 또는 날씨 API 등)일 수 있습니다.Toolformer는 외부 도구 API 사용을 위해 LLM을 미세 조정합니다.Function Calling은 도구 API 집합을 정의하고 이를 모델에 요청의 일부로 제공함으로써 LLM에 도구 사용 기능을 추가합니다.HuggingGPT는 다양한 기존 AI 모델을 연결하여 AI 작업을 해결하는 LLM 기반 에이전트로, LLM을 작업 계획자로 활용합니다.LLM 에이전트 응용 사례ChemCrow 에이전트는 유기 합성, 약물 발견 및 재료 설계를 포함한 작업을 완료하기 위해 설계되었음. 그림 출처: Bran et al., 2023복잡한 추론 및 상식 이해 능력 덕분에 LLM 기반 에이전트가 효과적으로 사용된 다양한 분야와 사례 연구를 강조합니다.주목할 만한 LLM 에이전트 사례Ma et'),\n",
       " Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 4227}, page_content='계획자로 활용합니다.LLM 에이전트 응용 사례ChemCrow 에이전트는 유기 합성, 약물 발견 및 재료 설계를 포함한 작업을 완료하기 위해 설계되었음. 그림 출처: Bran et al., 2023복잡한 추론 및 상식 이해 능력 덕분에 LLM 기반 에이전트가 효과적으로 사용된 다양한 분야와 사례 연구를 강조합니다.주목할 만한 LLM 에이전트 사례Ma et al. (2023)에서 정신 건강 지원을 위한 대화형 에이전트의 효과를 분석했는데, 이 에이전트는 사용자가 불안을 다루는 데 도움을 줄 수 있지만, 때때로 해로운 내용을 생성할 수 있다는 것을 발견했습니다.Horton (2023)에서 시뮬레이션 시나리오에서 인간의 경제 행동을 탐구하기 위해 LLM 기반 에이전트에 소유권, 선호도, 성격을 부여하는 연구를 진행했습니다.Generative Agents와 AgentSims는 가상 마을에서 인간의 일상 생활을 시뮬레이션하기 위해 여러 에이전트를 사용하는 프로젝트입니다.Blind Judgement는 여러 언어 모델을 활용해 다양한 판사들의 의사결정 과정을 시뮬레이션하며, 실제 대법원의 판결을 무작위 예측보다 더 정확하게 예측합니다.Ziems et al. (2023)은 요약 생성, 스크립팅, 키워드 추출과 같은 작업에서 연구자를 보조하는 에이전트를 개발했습니다.ChemCrow는 화학 관련 데이터베이스를 활용하여 해충 방제제, 세 가지 유기촉매 및 새로운 발색체의 발견을 독립적으로 계획하고 실행하는 LLM 화학 에이전트입니다.[Boiko 등(2023)]은 과학 실험의 설계, 계획 및 실행을 자동화하기 위해 여러 LLM을 결합한 연구를 진행했습니다.Math Agents는 수학 문제를 탐색, 발견, 해결 및 증명하는 데 연구자를 지원합니다. EduChat 및 CodeHelp는 교육 목적으로 설계된 주목할 만한 LLM 에이전트입니다.Mehta et al. (2023)은 인간 건축가들이 AI 에이전트와 상호 작용하여 3D 시뮬레이션 환경에서 구조물을 구축할 수 있는 상호 작용형'),\n",
       " Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 5026}, page_content='결합한 연구를 진행했습니다.Math Agents는 수학 문제를 탐색, 발견, 해결 및 증명하는 데 연구자를 지원합니다. EduChat 및 CodeHelp는 교육 목적으로 설계된 주목할 만한 LLM 에이전트입니다.Mehta et al. (2023)은 인간 건축가들이 AI 에이전트와 상호 작용하여 3D 시뮬레이션 환경에서 구조물을 구축할 수 있는 상호 작용형 프레임워크를 제안했습니다.ChatDev, ToolLLM, MetaGPT는 코딩, 디버깅, 테스팅을 자동화하고 기타 소프트웨어 엔지니어링 작업을 지원하는 데 AI 에이전트의 가능성을 보여주는 연구입니다.D-Bot은 데이터베이스 유지 관리 경험을 지속적으로 학습하는 LLM 기반 데이터베이스 관리자로, 데이터베이스에 대한 진단 및 최적화 조언을 제공합니다.IELLM은 석유 및 가스 산업의 도전 과제를 해결하기 위해 LLM을 적용한 사례입니다.Dasgupta 등 2023은 실체화된 추론 및 작업 계획을 위한 통합 에이전트 시스템을 제안했습니다.OS-Copilot은 운영 시스템(OS)의 여러 요소들과 웹, 코드 터미널, 파일, 멀티미디어 및 다양한 타사 애플리케이션과의 인터페이스를 구축할 수 있는 범용 에이전트 프레임워크입니다.LLM 에이전트 도구AutoGen 능력; 그림 출처:\\xa0https://microsoft.github.io/autogenLLM 에이전트를 구축하는 데 사용되는 주요 도구 및 프레임워크는 다음과 같습니다:LangChain: 언어 모델을 기반으로 한 애플리케이션 및 에이전트 개발을 위한 프레임워크입니다.AutoGPT: AI 에이전트를 구축하기 위한 다양한 도구를 제공합니다.Langroid: 다중 에이전트 프로그래밍을 통해 LLM 애플리케이션 구축을 간소화합니다. 이는 메시지를 통한 에이전트 간 협업을 중요하게 다룹니다.AutoGen: 여러 에이전트가 서로 대화하며 작업을 해결하는 LLM 애플리케이션 개발을 가능하게 하는 프레임워크입니다.OpenAgents: 언어 에이전트를 사용하고 호스팅하는 오픈'),\n",
       " Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 5825}, page_content='다양한 도구를 제공합니다.Langroid: 다중 에이전트 프로그래밍을 통해 LLM 애플리케이션 구축을 간소화합니다. 이는 메시지를 통한 에이전트 간 협업을 중요하게 다룹니다.AutoGen: 여러 에이전트가 서로 대화하며 작업을 해결하는 LLM 애플리케이션 개발을 가능하게 하는 프레임워크입니다.OpenAgents: 언어 에이전트를 사용하고 호스팅하는 오픈 플랫폼입니다.LlamaIndex: 대규모 언어 모델에 사용자 정의 데이터 소스를 연결하는 프레임워크입니다.GPT Engineer: 개발 작업을 완료하기 위한 코드 생성을 자동화하는 도구입니다.DemoGPT: 대화형 Streamlit 앱을 생성하는 자율 AI 에이전트입니다.GPT Researcher: 다양한 작업에 대한 종합적인 온라인 연구를 위해 설계된 자율 에이전트입니다.AgentVerse: 다양한 애플리케이션에서 여러 LLM 기반 에이전트의 배치를 용이하게 하도록 설계되었습니다.Agents: 자율 언어 에이전트를 구축하기 위한 오픈 소스 라이브러리/프레임워크입니다. 장단기 기억, 도구 사용, 웹 탐색, 다중 에이전트 통신 등을 지원하며 인간과 에이전트 간 상호작용 및 상징적 제어와 같은 새로운 기능도 지원합니다.BMTools: 언어 모델을 확장하기 위해 도구 사용을 지원하고, 커뮤니티가 도구를 구축하고 공유할 수 있는 플랫폼입니다.crewAI: 엔지니어를 위해 다시 구상된 AI 에이전트 프레임워크로, 강력한 기능을 간단하게 제공합니다.Phidata: 함수 호출을 사용해 AI 어시스턴트를 구축하기 위한 툴킷입니다.LLM 에이전트 평가AgentBench 벤치마크는 실제 세계의 도전과 8가지 다른 환경에서 LLM-as-Agent를 평가하기 위해 사용됩니다. 그림 출처: Liu et al. 2023LLM 자체를 평가하는 것처럼, LLM 에이전트를 평가하는 것도 어려운 작업입니다.  Wang et al. 2023에 따르면, 일반적인 평가 방법은 다음과 같습니다:인간 주석(Human Annotation): 인간'),\n",
       " Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 6622}, page_content='벤치마크는 실제 세계의 도전과 8가지 다른 환경에서 LLM-as-Agent를 평가하기 위해 사용됩니다. 그림 출처: Liu et al. 2023LLM 자체를 평가하는 것처럼, LLM 에이전트를 평가하는 것도 어려운 작업입니다.  Wang et al. 2023에 따르면, 일반적인 평가 방법은 다음과 같습니다:인간 주석(Human Annotation): 인간 평가자가 정직성, 유용성, 참여도, 편견 없음 등 애플리케이션에서 중요한 다양한 측면에서 LLM 결과를 직접 평가합니다.튜링 테스트(Turing Test): 인간 평가자는 실제 인간과 에이전트의 결과를 비교하여 구별할 수 없는 결과가 나오면 에이전트가 인간 수준의 성능을 달성했다고 볼 수 있습니다.메트릭(Metrics): 에이전트의 품질을 반영하기 위해 세심하게 설계된 지표들입니다. 주요 메트릭으로는 작업 성공률, 인간 유사성, 효율성 등이 있습니다.프로토콜(Protocols): 메트릭이 어떻게 사용되는지를 결정하는 일반적인 평가 방식입니다. 예를 들어 실제 세계 시뮬레이션, 사회적 평가, 다중 작업 평가, 소프트웨어 테스팅 등이 있습니다.벤치마크(Benchmarks): LLM 에이전트를 평가하기 위해 설계된 여러 벤치마크가 있습니다. 주목할 만한 예시로는 ALFWorld(opens in a new tab),\\xa0IGLU(opens in a new tab),\\xa0Tachikuma(opens in a new tab),\\xa0AgentBench(opens in a new tab),\\xa0SocKET(opens in a new tab),\\xa0AgentSims(opens in a new tab),\\xa0ToolBench(opens in a new tab),\\xa0WebShop(opens in a new tab),\\xa0Mobile-Env(opens in a new tab),\\xa0WebArena(opens in a new tab),\\xa0GentBench(opens in a new tab),\\xa0RocoBench(opens in a new'),\n",
       " Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 7414}, page_content='in a new tab),\\xa0ToolBench(opens in a new tab),\\xa0WebShop(opens in a new tab),\\xa0Mobile-Env(opens in a new tab),\\xa0WebArena(opens in a new tab),\\xa0GentBench(opens in a new tab),\\xa0RocoBench(opens in a new tab),\\xa0EmotionBench(opens in a new tab),\\xa0PEB(opens in a new tab),\\xa0ClemBench(opens in a new tab),\\xa0E2E(opens in a new tab) 등이 있습니다.도전과제LLM 에이전트는 아직 초기 단계이며, 구축 과정에는 많은 도전과 한계가 남아 있습니다:역할 수행 능력: LLM 기반 에이전트는 도메인에서 작업을 효과적으로 완료하기 위해 역할을 적응해야 합니다. LLM이 잘 표현하지 못하는 역할에 대해, 드문 역할이나 특이한 캐릭터를 대변하는 데이터로 LLM을 미세 조정할 수 있습니다.장기 계획 및 제한된 컨텍스트 길이: 장기적 계획 수립은 에이전트가 회복 불가능한 오류로 이어질 수 있는 도전적인 부분입니다. LLM의 지원 가능한 컨텍스트 길이에도 한계가 있어, 에이전트의 단기 기억 활용에 제한을 줄 수 있습니다.일반화된 인간 정렬: 다양한 인간 가치와 에이전트를 일치시키는 것은 표준 LLM과 함께 자주 발생하는 도전입니다. 고급 프롬프팅 전략을 설계하여 LLM을 재조정하는 것이 가능한 해결책 중 하나일 수 있습니다.프롬프트 견고성 및 신뢰성: LLM 에이전트는 메모리와 계획 등 다양한 모듈을 구동하는 여러 프롬프트를 포함할 수 있습니다. 프롬프트에 작은 변화만 있어도 LLM에서 신뢰성 문제가 발생하기 쉽습니다. LLM 에이전트는 전체 프롬프트 프레임워크를 포함하므로 견고성 문제에 더 취약할 수 있습니다. 잠재적 해결책으로는 프롬프트 요소를 시행착오를 통해 제작하거나, 프롬프트를 자동으로 최적화/조정하거나, GPT를 이용한 자동 프롬프트 생성 등이'),\n",
       " Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 8214}, page_content='여러 프롬프트를 포함할 수 있습니다. 프롬프트에 작은 변화만 있어도 LLM에서 신뢰성 문제가 발생하기 쉽습니다. LLM 에이전트는 전체 프롬프트 프레임워크를 포함하므로 견고성 문제에 더 취약할 수 있습니다. 잠재적 해결책으로는 프롬프트 요소를 시행착오를 통해 제작하거나, 프롬프트를 자동으로 최적화/조정하거나, GPT를 이용한 자동 프롬프트 생성 등이 있습니다. LLM과 마찬가지로, LLM 에이전트에서도 환각이 흔한 문제이며, 이 에이전트들은 외부 구성 요소와의 인터페이스를 위해 자연 언어에 의존하는데, 이로 인해 충돌하는 정보가 들어와 환각과 사실성 문제를 일으킬 수 있습니다.지식 경계: 지식 불일치로 인해 발생할 수 있는 환각이나 사실성 문제뿐만 아니라, LLM의 지식 범위를 제어하는 것도 어려워, 이는 시뮬레이션의 효과에 큰 영향을 미칠 수 있습니다. 구체적으로, LLM의 내부 지식은 편향을 도입하거나 사용자가 모르는 지식을 활용하여 특정 환경에서 작동할 때 에이전트의 행동에 영향을 줄 수 있습니다.효율성: LLM 에이전트는 LLM이 처리해야 하는 상당한 양의 요청을 포함하는데, 이는 LLM 추론 속도에 크게 의존할 수 있어 에이전트 작업의 효율성에 영향을 줄 수 있습니다. 여러 에이전트를 배치할 때 비용도 고려해야 할 사항입니다.참고 자료LLM Powered Autonomous AgentsMRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoningA Survey on Large Language Model based Autonomous AgentsThe Rise and Potential of Large Language Model Based Agents: A SurveyLarge Language Model based Multi-Agents: A Survey of'),\n",
       " Document(metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 9009}, page_content='and discrete reasoningA Survey on Large Language Model based Autonomous AgentsThe Rise and Potential of Large Language Model Based Agents: A SurveyLarge Language Model based Multi-Agents: A Survey of Progress and ChallengesCognitive Architectures for Language AgentsIntroduction to LLM AgentsLangChain AgentsBuilding Your First LLM Agent ApplicationBuilding LLM applications for productionAwesome LLM agentsAwesome LLM-Powered AgentFunctions, Tools and Agents with LangChain')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5193e01-6cf1-45b9-9ba5-38caf75162a6",
   "metadata": {
    "id": "f5193e01-6cf1-45b9-9ba5-38caf75162a6"
   },
   "source": [
    "### **문서 저장 (Storing documents)**\n",
    "\n",
    "이제 분할된 **텍스트 청크**를 인덱싱해야 합니다. 이를 통해 검색할 수 있습니다.  \n",
    "\n",
    "1. 각 **문서 청크**의 내용을 **임베딩(embedding)** 합니다.\n",
    "2. 이 **임베딩을 벡터 스토어(Vector Store)** 에 삽입합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b8da4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3e470628-33ba-4eb6-af96-d4b93e557c69', '009cb40b-64ea-439e-8e85-547586e1027e', 'fd9d8644-633e-4bf2-8fea-3ebfafa31987']\n"
     ]
    }
   ],
   "source": [
    "# 분할된 문서 청크(all_splits)는 임베딩되어 벡터 스토어에 저장됩니다.\n",
    "# 반환값은 저장된 각 문서 청크의 고유 ID 목록입니다.\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# 첫 세 개의 문서 ID를 출력합니다.\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57666234-a5b3-4abc-b079-755241bb2b98",
   "metadata": {
    "id": "57666234-a5b3-4abc-b079-755241bb2b98"
   },
   "source": [
    "이로써 **인덱싱(Indexing)** 단계가 완료되었습니다!\n",
    "\n",
    "- 이제 우리는 **질의 가능한 벡터 스토어**를 보유하고 있습니다.  \n",
    "- 블로그 게시물의 청크가 저장되어 있으며, 사용자 질문을 받으면 **관련 청크를 반환**할 수 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "## **2. 검색 및 생성 (Retrieval and Generation)**\n",
    "\n",
    "이제 실제 **애플리케이션 로직(application logic)** 을 작성해 보겠습니다.  \n",
    "간단한 애플리케이션을 만들어 다음과 같은 작업을 수행할 것입니다:  \n",
    "\n",
    "1. **사용자 질문을 입력받기**  \n",
    "2. **질문과 관련된 문서 청크 검색**  \n",
    "3. **검색된 문서와 질문을 모델에 전달**  \n",
    "4. **모델이 답변을 생성**  \n",
    "\n",
    "---\n",
    "\n",
    "- 생성 단계에서는 **챗 모델(Chat Model)** 을 사용할 것입니다.  \n",
    "- RAG용 프롬프트는 LangChain의 **[프롬프트 허브(prompt hub)](https://smith.langchain.com/hub/rlm/rag-prompt)** 에 저장되어 있습니다.\n",
    "```\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **프로세스 요약**  \n",
    "1. **사용자 질문 입력 → 문서 검색 → 답변 생성**  \n",
    "2. 관련 문서를 검색하고 질문과 함께 모델에 전달  \n",
    "3. 모델이 **최종 답변**을 생성  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdca94d3-3761-4bfc-9835-c29c49aa26db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# RAG에 최적화된 프롬프트를 LangChain Hub에서 가져옵니다.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ea7dd1-3add-4234-b5d9-8fc2c9392a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages[0].prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee032d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question 이 여기 들어갑니다.) \n",
      "Context: (context 내용이 여기 들어갑니다.) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트를 사용해 예제 메시지를 생성합니다.\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context 내용이 여기 들어갑니다.)\",\n",
    "     \"question\": \"(question 이 여기 들어갑니다.)\"}\n",
    ").to_messages()\n",
    "\n",
    "# 프롬프트로부터 생성된 메시지가 하나인지 확인\n",
    "assert len(example_messages) == 1\n",
    "\n",
    "# 첫 번째 메시지의 내용을 출력\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dfe84d-cc19-4227-bee4-56b69508ab11",
   "metadata": {
    "id": "77dfe84d-cc19-4227-bee4-56b69508ab11"
   },
   "source": [
    "**LangGraph**를 사용하여 **검색(Retrieval)** 과 **생성(Generation)** 단계를 하나의 애플리케이션으로 통합할 것입니다. 이를 통해 다음과 같은 이점을 얻을 수 있습니다:\n",
    "\n",
    "- **다양한 호출 모드 지원:**  \n",
    "  한 번 정의된 애플리케이션 로직은 **스트리밍(streaming)**, **비동기(async)**, **배치 호출(batched calls)** 등 여러 호출 모드를 자동으로 지원합니다.\n",
    "\n",
    "- **간편한 배포:**  \n",
    "  [**LangGraph 플랫폼**](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/)을 통해 애플리케이션을 더 쉽게 배포할 수 있습니다.\n",
    "\n",
    "- **자동 추적:**  \n",
    "  **LangSmith**가 애플리케이션의 모든 단계를 자동으로 추적합니다.\n",
    "\n",
    "- **확장성:**  \n",
    "  [**데이터 지속성(persistence)**](https://langchain-ai.github.io/langgraph/concepts/persistence/) 및 [**사람의 승인(Human-in-the-loop approval)**](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)과 같은 핵심 기능을 최소한의 코드 변경으로 손쉽게 추가할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## **LangGraph를 사용하기 위한 3가지 핵심 요소**\n",
    "\n",
    "1. **애플리케이션의 상태(State)**  \n",
    "2. **애플리케이션의 노드(Nodes)** - 각 단계의 로직  \n",
    "3. **애플리케이션의 흐름(Control Flow)** - 예) 단계의 순서 및 실행 흐름\n",
    "\n",
    "---\n",
    "\n",
    "### **1. 상태(State)**\n",
    "\n",
    "애플리케이션의 [**상태(state)**](https://langchain-ai.github.io/langgraph/concepts/low_level/#state)는 다음을 관리합니다:  \n",
    "- 애플리케이션에 입력되는 데이터  \n",
    "- 각 단계 간에 전달되는 데이터  \n",
    "- 애플리케이션에서 최종적으로 출력되는 데이터  \n",
    "\n",
    "**상태(State)** 는 일반적으로 `TypedDict`로 정의하지만, 더 정교한 검증과 유연성이 필요하다면 [Pydantic BaseModel](https://langchain-ai.github.io/langgraph/how-tos/state-model/)을 사용할 수 있습니다.\n",
    "- TypedDict: 간단하게 상태의 구조(예: 어떤 데이터가 어떤 형태로 들어와야 하는지)를 정의할 때 사용  \n",
    "- Pydantic BaseModel: 더 복잡한 데이터 검증, 기본값 설정, 사용자 정의 검증 등을 할 때 사용\n",
    "\n",
    "---\n",
    "\n",
    "### **간단한 RAG 애플리케이션 상태 예시**\n",
    "\n",
    "간단한 **RAG 애플리케이션**에서는 다음 항목만 추적하면 됩니다:  \n",
    "1. **입력 질문(question)**  \n",
    "2. **검색된 문맥(retrieved context)**  \n",
    "3. **생성된 답변(generated answer)**  \n",
    "\n",
    "다음 단계에서는 **노드(Nodes)** 를 정의하여 각 애플리케이션 단계를 설정하는 방법을 살펴보겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7bab225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# List: 여러 Document 객체를 리스트로 저장할 때 사용\n",
    "# TypedDict: 상태(State) 객체 정의를 위한 구조체 역할\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# 애플리케이션의 상태(State) 객체 정의\n",
    "class State(TypedDict):\n",
    "    question: str          # 사용자 질문을 저장하는 문자열 필드\n",
    "    context: List[Document]    # 검색된 문서 목록을 저장하는 필드\n",
    "    answer: str           # 생성된 답변을 저장하는 문자열 필드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77868d9a-892f-4b2c-b706-850f96b4464f",
   "metadata": {
    "id": "77868d9a-892f-4b2c-b706-850f96b4464f"
   },
   "source": [
    "#### **노드 (애플리케이션 단계)**\n",
    "\n",
    "간단한 두 단계로 구성된 시퀀스를 정의해 보겠습니다:  \n",
    "\n",
    "1. **검색 (Retrieval)**  \n",
    "2. **생성 (Generation)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "121cb602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자의 질문을 기반으로 벡터 스토어에서 관련 문서를 검색\n",
    "def retrieve(state: State):\n",
    "    # 벡터 스토어에서 질문과 유사도가 높은 문서를 검색\n",
    "    retrieved_docs = vector_store.similarity_search(state['question'])\n",
    "    return {\"context\": retrieved_docs}  #artifact 반환\n",
    "    \n",
    "# 검색된 문서와 질문을 기반으로 모델이 답변을 생성\n",
    "def generate(state: State):\n",
    "    # 검색된 문서(context) 내용을 하나의 문자열로 합칩니다. -> 직렬화\n",
    "    combined_context = \"\\n\\n\".join(doc.page_content for doc in state['context'])\n",
    "    \n",
    "    # 프롬프트에 질문과 직렬화된 문서 내용을 전달하여 메시지 생성\n",
    "    messages = prompt.invoke({\"context\": combined_context, \"question\": state[\"question\"]})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac9dc3-d73d-48c3-be05-4b60e0b8bc17",
   "metadata": {
    "id": "d1ac9dc3-d73d-48c3-be05-4b60e0b8bc17"
   },
   "source": [
    "애플리케이션을 하나의 **`graph` 객체**로 컴파일합니다.  여기서는 **검색 단계**와 **생성 단계**를 **단일 시퀀스(sequence)** 로 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d8eb0f-2045-45b8-b09f-5e9d1c558d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000024CFC24D950>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "# StateGraph 초기화\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# 검색(retrieve)과 생성(generate) 단계를 순차적으로 실행하도록 설정 (node 자동 추가)\n",
    "workflow.add_sequence([retrieve, generate])\n",
    "\n",
    "# 그래프의 시작점(START)을 'retrieve' 단계와 연결\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "\n",
    "# 그래프를 컴파일하여 최종 그래프 객체를 생성\n",
    "app = workflow.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "768c7af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: LLM 에이전트 프레임워크의 핵심 구성 요소는 사용자 요청(User Request), 에이전트(Agent)/두뇌(Brain) 역할을 하는 대규모 언어 모델(LLM), 계획(Planning), 메모리(Memory), 그리고 외부 도구(Tools)입니다. 계획과 메모리 모듈은 에이전트가 과거 행동을 관리하고 미래 행동을 계획하는 데 도움을 주며, 도구는 외부 데이터베이스나 API 등과 상호작용하게 합니다. 이러한 요소들이 결합되어 복잡한 작업 흐름을 관리하고 사용자 요청에 효과적으로 대응할 수 있게 합니다.\n"
     ]
    }
   ],
   "source": [
    "# 그래프를 호출하여 사용자 질문에 대한 답변을 생성\n",
    "result = app.invoke({\"question\": \"LLM 에이전트 프레임워크를 구성하는 핵심 구성 요소는 무엇인가요?\"})\n",
    "\n",
    "# 질문\n",
    "#print(f'Question: {result[\"question\"]}\\n\\n')\n",
    "\n",
    "# 문서의 출처\n",
    "#print(f'Context: {result[\"context\"][0].metadata}\\n\\n')\n",
    "\n",
    "# 생성된 답변(Answer)을 출력\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tjC2SdXftfcz",
   "metadata": {
    "id": "tjC2SdXftfcz"
   },
   "source": [
    "-----------------\n",
    "**LangGraph**는 RAG 애플리케이션을 구축하는 데 반드시 필요하지는 않습니다. 실제로 개별 구성 요소를 사용하여 동일한 애플리케이션 로직을 구현할 수도 있습니다. \n",
    "그럼에도 LangGraph를 사용하는 이유는 복잡한 워크플로우 관리, 상태 관리 및 공유, 에이전트 간 협업 강화, 유연성과 확장성 때문 입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a062bcfe-615b-46cd-a4f4-3b87887ff911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toolformer는 대규모 언어 모델(LLM)을 외부 도구 API를 사용하는 방식으로 미세 조정하여, LLM이 필요한 작업에서 외부 도구(예: 검색, 코드 실행 등)를 자동으로 활용할 수 있게 돕는 역할을 합니다. 이를 통해 LLM이 도구와 효과적으로 상호작용하며 작업을 수행할 수 있도록 만듭니다.\n"
     ]
    }
   ],
   "source": [
    "# Langgraph 없이 RAG 구현한 경우\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "question = \"Toolformer가 하는 일이 뭔가요?\"\n",
    "\n",
    "# 벡터 스토어에서 질문과 유사한 문서 검색\n",
    "retrieved_docs = vector_store.similarity_search(question)\n",
    "\n",
    "# 검색된 문서들의 내용을 하나의 문자열로 결합\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "# 검색된 문서(Context)와 질문을 프롬프트 템플릿에 전달하여 메시지 생성\n",
    "message = prompt.invoke({\"question\": question, \"context\": docs_content}).to_messages()\n",
    "\n",
    "# LLM(대형 언어 모델)을 호출하여 답변 생성\n",
    "answer = llm.invoke(message)\n",
    "\n",
    "# 생성된 답변 출력\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef88f30-40ca-476b-808d-794cb72d401f",
   "metadata": {
    "id": "4ef88f30-40ca-476b-808d-794cb72d401f"
   },
   "source": [
    "<br>\n",
    "\n",
    "**LangGraph**는 다양한 호출 모드(**동기(sync)**, **비동기(async)**, **스트리밍(streaming)**)를 지원합니다.  \n",
    "\n",
    "###  **스트림 단계(Stream Steps) 반환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f51436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='d2323daa-faef-434f-ac21-4145b468ca7d', metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 4227}, page_content='계획자로 활용합니다.LLM 에이전트 응용 사례ChemCrow 에이전트는 유기 합성, 약물 발견 및 재료 설계를 포함한 작업을 완료하기 위해 설계되었음. 그림 출처: Bran et al., 2023복잡한 추론 및 상식 이해 능력 덕분에 LLM 기반 에이전트가 효과적으로 사용된 다양한 분야와 사례 연구를 강조합니다.주목할 만한 LLM 에이전트 사례Ma et al. (2023)에서 정신 건강 지원을 위한 대화형 에이전트의 효과를 분석했는데, 이 에이전트는 사용자가 불안을 다루는 데 도움을 줄 수 있지만, 때때로 해로운 내용을 생성할 수 있다는 것을 발견했습니다.Horton (2023)에서 시뮬레이션 시나리오에서 인간의 경제 행동을 탐구하기 위해 LLM 기반 에이전트에 소유권, 선호도, 성격을 부여하는 연구를 진행했습니다.Generative Agents와 AgentSims는 가상 마을에서 인간의 일상 생활을 시뮬레이션하기 위해 여러 에이전트를 사용하는 프로젝트입니다.Blind Judgement는 여러 언어 모델을 활용해 다양한 판사들의 의사결정 과정을 시뮬레이션하며, 실제 대법원의 판결을 무작위 예측보다 더 정확하게 예측합니다.Ziems et al. (2023)은 요약 생성, 스크립팅, 키워드 추출과 같은 작업에서 연구자를 보조하는 에이전트를 개발했습니다.ChemCrow는 화학 관련 데이터베이스를 활용하여 해충 방제제, 세 가지 유기촉매 및 새로운 발색체의 발견을 독립적으로 계획하고 실행하는 LLM 화학 에이전트입니다.[Boiko 등(2023)]은 과학 실험의 설계, 계획 및 실행을 자동화하기 위해 여러 LLM을 결합한 연구를 진행했습니다.Math Agents는 수학 문제를 탐색, 발견, 해결 및 증명하는 데 연구자를 지원합니다. EduChat 및 CodeHelp는 교육 목적으로 설계된 주목할 만한 LLM 에이전트입니다.Mehta et al. (2023)은 인간 건축가들이 AI 에이전트와 상호 작용하여 3D 시뮬레이션 환경에서 구조물을 구축할 수 있는 상호 작용형'), Document(id='3e470628-33ba-4eb6-af96-d4b93e557c69', metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 1}, page_content='LLM Agents\\nPrompt Engineering Guide 한글화 - LLM Agents\\nLLM AgentsLLM 에이전트 프레임워크에이전트계획피드백이 없는 계획피드백이 있는 계획메모리도구LLM 에이전트 응용 사례주목할 만한 LLM 에이전트 사례LLM 에이전트 도구LLM 에이전트 평가도전과제참고 자료ResumeBlog\\nLLM Agents\\nPrompt Engineering Guide 한글화 - LLM Agents'), Document(id='f073f84b-eec9-470d-a415-c71b6473d1c7', metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 3428}, page_content='형식도 있습니다. 여기에는 자연 언어, 임베딩, 데이터베이스, 구조화된 리스트 등이 포함되며, 이들은 자연 언어로 표현된 키와 임베딩 벡터로 표현된 값으로 구성된 키-값 구조를 활용하는 Minecraft의 Ghost (GITM)와 같이 결합될 수 있습니다.계획 및 메모리 모듈은 에이전트가 동적 환경에서 효과적으로 작동하고 과거 행동을 잘 회상하며 미래 행동을 계획할 수 있도록 합니다.도구도구는 LLM 에이전트가 외부 환경과 상호 작용하는 데 도움을 주는 도구나 도구 집합을 의미합니다. 여기에는 위키피디아 검색 API, 코드 인터프리터, 수학 엔진 등이 포함됩니다. 또한, 데이터베이스, 지식 베이스, 외부 모델도 도구에 포함될 수 있습니다. 에이전트가 외부 도구와 상호작용할 때는 사용자 요청을 충족시키고 부분 작업을 완료하기 위해 필요한 관찰이나 정보를 얻는 워크플로우를 통해 작업을 수행합니다. 예를 들어, 건강 관련 질문에서 코드 인터프리터는 사용자가 요청한 필요한 차트 정보를 생성하는 코드를 실행하는 도구가 됩니다.LLM은 다양한 방식으로 도구를 활용합니다:MRKL은 LLM과 전문가 모듈을 결합한 프레임워크로, 이는 LLM 또는 기호식(계산기 또는 날씨 API 등)일 수 있습니다.Toolformer는 외부 도구 API 사용을 위해 LLM을 미세 조정합니다.Function Calling은 도구 API 집합을 정의하고 이를 모델에 요청의 일부로 제공함으로써 LLM에 도구 사용 기능을 추가합니다.HuggingGPT는 다양한 기존 AI 모델을 연결하여 AI 작업을 해결하는 LLM 기반 에이전트로, LLM을 작업 계획자로 활용합니다.LLM 에이전트 응용 사례ChemCrow 에이전트는 유기 합성, 약물 발견 및 재료 설계를 포함한 작업을 완료하기 위해 설계되었음. 그림 출처: Bran et al., 2023복잡한 추론 및 상식 이해 능력 덕분에 LLM 기반 에이전트가 효과적으로 사용된 다양한 분야와 사례 연구를 강조합니다.주목할 만한 LLM 에이전트 사례Ma et'), Document(id='009cb40b-64ea-439e-8e85-547586e1027e', metadata={'source': 'https://harheem.github.io/llm/2024/02/28/llm-agents.html', 'start_index': 236}, page_content='LLM AgentsPrompt Engineering Guide - LLM AgentsTranslate llm-agents.en.mdx to Korean in llm-agents.kr.mdx by harheem · Pull Request #406 · dair-ai/Prompt-Engineering-GuideLLM 기반 에이전트는 계획 및 메모리와 같은 핵심 모듈과 결합된 LLM을 통해 복잡한 작업을 수행할 수 있는 LLM 애플리케이션을 의미합니다. 여기서 LLM은 작업이나 사용자 요청을 완료하는 데 필요한 작업 흐름을 제어하는 주요 컨트롤러 또는 ‘두뇌’ 역할을 합니다. LLM 에이전트는 계획, 메모리, 도구와 같은 다양한 핵심 모듈이 필요할 수 있습니다.이 LLM 에이전트의 유용성을 더 잘 이해하기 위해, 다음과 같은 시스템을 구축하는 데 관심이 있다고 생각해 보겠습니다:2023년 미국의 평균 일일 칼로리 섭취량은 얼마인가요?위 질문은 이미 충분한 지식을 갖춘 LLM을 통해 바로 답할 수 있을 것입니다. 만약 LLM이 해당 질문에 대한 지식이 없다면, LLM은 건강 관련 정보나 보고서에 접근할 수 있는 간단한 RAG 시스템을 활용할 수 있습니다. 이제 보다 복잡한 질문을 시도해 보겠습니다:지난 10년 동안 미국 성인의 평균 일일 칼로리 섭취 추세는 어떻게 변했으며, 이것이 비만률에 어떤 영향을 미쳤나요? 또한, 이 기간 동안 비만률 추세의 그래픽 표현을 제공할 수 있나요?이 질문에 대답하기 위해서는 단순히 LLM만 사용하는 것으로는 충분하지 않습니다. LLM을 외부 지식 베이스와 결합한 RAG 시스템을 만드는 것도 이런 복잡한 질문에 대한 답변을 제공하기엔 부족할 수 있습니다. 이런 질문에 대응하기 위해서는 LLM이 필요한 도구를 활용하고, 목표로 하는 최종 응답을 위한 작업 흐름을 관리하며, 작업을 세분화하는 과정이 필요합니다. 한 가지 해결책으로는 LLM 에이전트를 구축하여 검색 API, 건강 관련 출판물, 칼로리 섭취 및 비만과 관련된 정보를 제공하는')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': '주목할 만한 LLM 에이전트 사례로는 ChemCrow(유기 합성, 약물 발견, 재료 설계 자동화), Ma et al.(2023)의 정신 건강 지원 대화형 에이전트, Horton(2023)의 경제 행동 시뮬레이션 에이전트, Generative Agents 및 AgentSims(가상 마을 생활 시뮬레이션), Blind Judgement(판사 의사결정 시뮬레이션) 등이 있습니다. 이들 에이전트는 다양한 분야에서 복잡한 추론과 도구 활용을 통해 효과적으로 사용되고 있습니다.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 그래프의 각 단계를 스트리밍 모드로 실행\n",
    "# - stream_mode=\"updates\": 각 단계가 완료될 때마다 업데이트를 반환\n",
    "# - stream_mode=\"values\": 최종 응답값만 반환\n",
    "for step in app.stream(\n",
    "    {\"question\": \"주목할 만한 LLM 에이전트 사례를 알려주세요.\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")    # 각 단계의 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ffb5936-f868-4844-9d65-dbe11542f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주목할 만한 LLM 에이전트 사례로는 ChemCrow가 있으며, 이는 유기 합성, 약물 발견, 재료 설계 작업을 독립적으로 계획하고 실행하는 화학 분야 에이전트입니다. 또한 정신 건강 지원 대화형 에이전트(Ma et al., 2023), 인간 경제 행동 시뮬레이션 에이전트(Horton, 2023), 가상 마을 생활 시뮬레이션을 위한 Generative Agents와 AgentSims 등이 있습니다. Blind Judgement는 다수의 언어 모델로 실제 대법원 판결을 예측하는 사례로도 유명합니다.\n"
     ]
    }
   ],
   "source": [
    "for step in app.stream(\n",
    "    {\"question\": \"주목할 만한 LLM 에이전트 사례를 알려주세요.\"},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    if \"generate\" in step:\n",
    "        print(step[\"generate\"][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01a025-05e3-4d8e-b81a-3b75539cc645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
